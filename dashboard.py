import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
from datetime import datetime, date, timedelta
import os
import requests
import json
import time

# .env íŒŒì¼ ë¡œë“œ (ì„ íƒì‚¬í•­)
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass  # python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš° ë¬´ì‹œ

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ê³¨í”„ ë‚ ì”¨ íŠ¸ë Œë“œ ëŒ€ì‹œë³´ë“œ",
    page_icon="â›³",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼ë§
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #2E8B57;
        text-align: center;
        margin-bottom: 2rem;
        font-weight: bold;
    }
    .metric-card {
        background-color: #f0f8ff;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #2E8B57;
        margin: 0.5rem 0;
    }
    .weather-card {
        padding: 1rem;
        border-radius: 10px;
        text-align: center;
        margin: 0.5rem;
    }
    .rain-card { background-color: #e3f2fd; }
    .snow-card { background-color: #f3e5f5; }
    .dry-card { background-color: #fff3e0; }
    .mixed-card { background-color: #f1f8e9; }
</style>
""", unsafe_allow_html=True)

def fetch_naver_datalab_daily(keyword_groups, start_date, end_date):
    """ë„¤ì´ë²„ ë°ì´í„°ë©ì—ì„œ ê²€ìƒ‰ íŠ¸ë Œë“œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    url = "https://openapi.naver.com/v1/datalab/search"
    
    # API í‚¤ ê°€ì ¸ì˜¤ê¸° (í™˜ê²½ë³€ìˆ˜ -> Streamlit secrets ìˆœì„œ)
    client_id = os.environ.get("NAVER_CLIENT_ID")
    client_secret = os.environ.get("NAVER_CLIENT_SECRET")
    
    # Streamlit secretsì—ì„œ ì‹œë„
    if not client_id or not client_secret:
        try:
            import streamlit as st
            if hasattr(st, 'secrets') and 'NAVER_CLIENT_ID' in st.secrets:
                client_id = st.secrets['NAVER_CLIENT_ID']
                client_secret = st.secrets['NAVER_CLIENT_SECRET']
        except:
            pass
    
    headers = {
        "X-Naver-Client-Id": client_id,
        "X-Naver-Client-Secret": client_secret,
        "Content-Type": "application/json",
    }
    
    if not client_id or not client_secret:
        st.error("âš ï¸ ë„¤ì´ë²„ API ìê²©ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.info("""
        **API í‚¤ ì„¤ì • ë°©ë²•:**
        1. **ë¡œì»¬ ì‹¤í–‰**: í™˜ê²½ë³€ìˆ˜ ì„¤ì •
           ```bash
           export NAVER_CLIENT_ID="your_client_id"
           export NAVER_CLIENT_SECRET="your_client_secret"
           ```
        2. **Streamlit Cloud**: Secretsì—ì„œ ì„¤ì •
           - Settings â†’ Secrets â†’ ë‹¤ìŒ ë‚´ìš© ì¶”ê°€:
           ```
           NAVER_CLIENT_ID = "your_client_id"
           NAVER_CLIENT_SECRET = "your_client_secret"
           ```
        """)
        return None
    
    body = {
        "startDate": start_date,
        "endDate": end_date,
        "timeUnit": "date",
        "keywordGroups": keyword_groups,
    }
    
    try:
        resp = requests.post(url, headers=headers, data=json.dumps(body), timeout=60)
        resp.raise_for_status()
        data = resp.json()
        
        rows = []
        for group in data.get("results", []):
            gname = group["title"]
            for item in group["data"]:
                rows.append({
                    "date": item["period"],
                    "group": gname,
                    "ratio": item["ratio"]
                })
        
        df = pd.DataFrame(rows)
        if not df.empty:
            df["date"] = pd.to_datetime(df["date"]).dt.date
        return df
        
    except requests.exceptions.RequestException as e:
        st.error(f"ë„¤ì´ë²„ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None
    except Exception as e:
        st.error(f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None

def fetch_open_meteo_daily(lat, lon, start_date, end_date, tz):
    """Open-Meteoì—ì„œ ë‚ ì”¨ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
    base_url = "https://archive-api.open-meteo.com/v1/archive"
    params = {
        "latitude": lat,
        "longitude": lon,
        "start_date": start_date,
        "end_date": end_date,
        "daily": "precipitation_sum,rain_sum,snowfall_sum",
        "timezone": tz,
    }
    
    try:
        r = requests.get(base_url, params=params, timeout=60)
        r.raise_for_status()
        js = r.json()
        daily = js.get("daily", {})
        
        df = pd.DataFrame({
            "date": pd.to_datetime(daily.get("time", [])).date,
            "precipitation_sum": daily.get("precipitation_sum", []),
            "rain_sum": daily.get("rain_sum", []),
            "snowfall_sum": daily.get("snowfall_sum", []),
        })
        return df
        
    except requests.exceptions.RequestException as e:
        st.error(f"ë‚ ì”¨ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None
    except Exception as e:
        st.error(f"ë‚ ì”¨ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return None

def classify_weather(row, rain_threshold=1.0, snow_threshold=1.0):
    """ë‚ ì”¨ ë¶„ë¥˜"""
    rain = row.get("rain_sum", 0.0) or 0.0
    snow = row.get("snowfall_sum", 0.0) or 0.0
    
    if rain >= rain_threshold and snow >= snow_threshold:
        return "mixed"
    if snow >= snow_threshold:
        return "snow"
    if rain >= rain_threshold:
        return "rain"
    return "dry"

@st.cache_data(ttl=300)  # 5ë¶„ ìºì‹œ
def load_data_with_keywords(keyword_groups, start_date, end_date, lat=37.5665, lon=126.9780, tz="Asia/Seoul"):
    """í‚¤ì›Œë“œì™€ ë‚ ì§œë¥¼ ë°›ì•„ì„œ ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬"""
    # ë„¤ì´ë²„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    df_trend = fetch_naver_datalab_daily(keyword_groups, start_date, end_date)
    if df_trend is None or df_trend.empty:
        return None, None
    
    # ë‚ ì”¨ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    df_wx = fetch_open_meteo_daily(lat, lon, start_date, end_date, tz)
    if df_wx is None or df_wx.empty:
        return None, None
    
    # ë°ì´í„° ë³‘í•©
    merged = pd.merge(df_trend, df_wx, on="date", how="inner")
    merged["day_type"] = merged.apply(classify_weather, axis=1)
    
    # ìš”ì•½ í†µê³„ ìƒì„±
    summary = (
        merged.groupby(["group", "day_type"])["ratio"]
        .mean()
        .reset_index()
        .pivot(index="group", columns="day_type", values="ratio")
        .fillna(0.0)
    )
    
    # dry ëŒ€ë¹„ ì°¨ì´ ê³„ì‚°
    for t in ["rain", "snow", "mixed"]:
        if "dry" in summary.columns:
            summary[f"{t}_vs_dry"] = summary.get(t, 0.0) - summary["dry"]
    
    summary = summary.reset_index()
    
    return merged, summary

@st.cache_data
def load_data():
    """ê¸°ì¡´ CSV íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë”© (ë°±ì—…ìš©)"""
    try:
        # ì¼ë³„ ë°ì´í„° ë¡œë”©
        daily_df = pd.read_csv('naver_golf_trend_weather_daily_2024.csv')
        daily_df['date'] = pd.to_datetime(daily_df['date'])
        
        # ìš”ì•½ ë°ì´í„° ë¡œë”©
        summary_df = pd.read_csv('naver_golf_trend_weather_summary_2024.csv')
        
        return daily_df, summary_df
    except FileNotFoundError as e:
        st.error(f"ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        st.info("ë¨¼ì € golf_weather_naverdatalab_2024.py ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return None, None

def create_weather_metrics(summary_df):
    """ë‚ ì”¨ë³„ ë©”íŠ¸ë¦­ ì¹´ë“œ ìƒì„±"""
    if summary_df is None:
        return
    
    col1, col2, col3, col4 = st.columns(4)
    
    weather_types = ['dry', 'rain', 'snow', 'mixed']
    weather_names = ['ê±´ì¡°', 'ë¹„', 'ëˆˆ', 'í˜¼í•©']
    weather_colors = ['#FFA726', '#42A5F5', '#AB47BC', '#66BB6A']
    
    for i, (weather, name, color) in enumerate(zip(weather_types, weather_names, weather_colors)):
        with [col1, col2, col3, col4][i]:
            if weather in summary_df.columns:
                avg_ratio = summary_df[weather].mean()
                st.markdown(f"""
                <div class="weather-card {weather}-card">
                    <h3 style="color: {color}; margin: 0;">{name}</h3>
                    <h2 style="margin: 0.5rem 0;">{avg_ratio:.2f}</h2>
                    <p style="margin: 0; font-size: 0.9rem;">í‰ê·  ê²€ìƒ‰ ë¹„ìœ¨</p>
                </div>
                """, unsafe_allow_html=True)

def create_trend_chart(daily_df):
    """ì‹œê³„ì—´ íŠ¸ë Œë“œ ì°¨íŠ¸ ìƒì„±"""
    if daily_df is None:
        return
    
    fig = px.line(
        daily_df, 
        x='date', 
        y='ratio', 
        color='group',
        title='ê³¨í”„ ê´€ë ¨ ê²€ìƒ‰ íŠ¸ë Œë“œ (2024ë…„)',
        labels={'ratio': 'ê²€ìƒ‰ ë¹„ìœ¨', 'date': 'ë‚ ì§œ', 'group': 'í‚¤ì›Œë“œ ê·¸ë£¹'}
    )
    
    fig.update_layout(
        height=500,
        xaxis_title="ë‚ ì§œ",
        yaxis_title="ê²€ìƒ‰ ë¹„ìœ¨",
        legend_title="í‚¤ì›Œë“œ ê·¸ë£¹",
        hovermode='x unified'
    )
    
    st.plotly_chart(fig, use_container_width=True)

def create_weather_comparison_chart(summary_df):
    """ë‚ ì”¨ë³„ ë¹„êµ ì°¨íŠ¸ ìƒì„±"""
    if summary_df is None:
        return
    
    # ë°ì´í„° ì¤€ë¹„
    weather_cols = [col for col in ['dry', 'rain', 'snow', 'mixed'] if col in summary_df.columns]
    
    if not weather_cols:
        st.warning("ë‚ ì”¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë§‰ëŒ€ ì°¨íŠ¸ ìƒì„±
    fig = go.Figure()
    
    colors = {'dry': '#FFA726', 'rain': '#42A5F5', 'snow': '#AB47BC', 'mixed': '#66BB6A'}
    weather_names = {'dry': 'ê±´ì¡°', 'rain': 'ë¹„', 'snow': 'ëˆˆ', 'mixed': 'í˜¼í•©'}
    
    for weather in weather_cols:
        fig.add_trace(go.Bar(
            name=weather_names[weather],
            x=summary_df['group'],
            y=summary_df[weather],
            marker_color=colors[weather],
            text=summary_df[weather].round(2),
            textposition='auto'
        ))
    
    fig.update_layout(
        title='í‚¤ì›Œë“œë³„ ë‚ ì”¨ì— ë”°ë¥¸ ê²€ìƒ‰ ë¹„ìœ¨ ë¹„êµ',
        xaxis_title='í‚¤ì›Œë“œ ê·¸ë£¹',
        yaxis_title='í‰ê·  ê²€ìƒ‰ ë¹„ìœ¨',
        barmode='group',
        height=500
    )
    
    st.plotly_chart(fig, use_container_width=True)

def create_weather_distribution_chart(daily_df):
    """ë‚ ì”¨ ë¶„í¬ íŒŒì´ ì°¨íŠ¸ ìƒì„±"""
    if daily_df is None:
        return
    
    weather_counts = daily_df['day_type'].value_counts()
    weather_names = {'dry': 'ê±´ì¡°', 'rain': 'ë¹„', 'snow': 'ëˆˆ', 'mixed': 'í˜¼í•©'}
    
    fig = px.pie(
        values=weather_counts.values,
        names=[weather_names.get(w, w) for w in weather_counts.index],
        title='2024ë…„ ë‚ ì”¨ ë¶„í¬',
        color_discrete_sequence=['#FFA726', '#42A5F5', '#AB47BC', '#66BB6A']
    )
    
    fig.update_traces(textposition='inside', textinfo='percent+label')
    st.plotly_chart(fig, use_container_width=True)

def create_correlation_heatmap(daily_df):
    """ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ ìƒì„±"""
    if daily_df is None:
        return
    
    # ë‚ ì”¨ë¥¼ ë”ë¯¸ ë³€ìˆ˜ë¡œ ë³€í™˜
    weather_dummies = pd.get_dummies(daily_df['day_type'], prefix='weather')
    numeric_df = daily_df[['ratio']].join(weather_dummies)
    
    # ê·¸ë£¹ë³„ë¡œ ìƒê´€ê´€ê³„ ê³„ì‚°
    correlation_data = []
    for group in daily_df['group'].unique():
        group_data = numeric_df[daily_df['group'] == group]
        corr = group_data.corr()['ratio'].drop('ratio')
        correlation_data.append({
            'group': group,
            **corr.to_dict()
        })
    
    corr_df = pd.DataFrame(correlation_data).set_index('group')
    
    fig = px.imshow(
        corr_df.T,
        title='í‚¤ì›Œë“œ ê·¸ë£¹ë³„ ë‚ ì”¨ì™€ ê²€ìƒ‰ ë¹„ìœ¨ ìƒê´€ê´€ê³„',
        color_continuous_scale='RdBu_r',
        aspect='auto'
    )
    
    fig.update_layout(height=400)
    st.plotly_chart(fig, use_container_width=True)

def main():
    # í—¤ë”
    st.markdown('<h1 class="main-header">â›³ ê³¨í”„ ë‚ ì”¨ íŠ¸ë Œë“œ ëŒ€ì‹œë³´ë“œ</h1>', unsafe_allow_html=True)
    
    # ì‚¬ì´ë“œë°”
    st.sidebar.header("ğŸ”§ ì„¤ì •")
    
    # ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ
    data_source = st.sidebar.radio(
        "ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ",
        ["ì‹¤ì‹œê°„ API í˜¸ì¶œ", "ê¸°ì¡´ CSV íŒŒì¼"],
        help="ì‹¤ì‹œê°„ API í˜¸ì¶œì„ ì„ íƒí•˜ë©´ ë„¤ì´ë²„ ë°ì´í„°ë©ì—ì„œ ìµœì‹  ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."
    )
    
    if data_source == "ì‹¤ì‹œê°„ API í˜¸ì¶œ":
        # API ìê²©ì¦ëª… í™•ì¸
        if not os.environ.get("NAVER_CLIENT_ID") or not os.environ.get("NAVER_CLIENT_SECRET"):
            st.sidebar.error("âš ï¸ ë„¤ì´ë²„ API ìê²©ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            st.sidebar.info("í„°ë¯¸ë„ì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
            st.sidebar.code("""
export NAVER_CLIENT_ID="your_client_id"
export NAVER_CLIENT_SECRET="your_client_secret"
            """)
            st.stop()
        
        # í‚¤ì›Œë“œ ì…ë ¥
        st.sidebar.subheader("ğŸ” í‚¤ì›Œë“œ ì„¤ì •")
        
        # í‚¤ì›Œë“œ ê·¸ë£¹ ìˆ˜
        num_groups = st.sidebar.number_input(
            "í‚¤ì›Œë“œ ê·¸ë£¹ ìˆ˜",
            min_value=1,
            max_value=5,
            value=2,
            help="ìµœëŒ€ 5ê°œê¹Œì§€ í‚¤ì›Œë“œ ê·¸ë£¹ì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )
        
        keyword_groups = []
        for i in range(num_groups):
            st.sidebar.write(f"**ê·¸ë£¹ {i+1}**")
            group_name = st.sidebar.text_input(
                f"ê·¸ë£¹ëª… {i+1}",
                value=f"ê·¸ë£¹{i+1}",
                key=f"group_name_{i}"
            )
            
            keywords_input = st.sidebar.text_input(
                f"í‚¤ì›Œë“œ {i+1} (ì‰¼í‘œë¡œ êµ¬ë¶„)",
                value="ê³¨í”„" if i == 0 else "",
                help="ì—¬ëŸ¬ í‚¤ì›Œë“œëŠ” ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„í•˜ì„¸ìš”. ì˜ˆ: ê³¨í”„, ë¼ìš´ë”©",
                key=f"keywords_{i}"
            )
            
            if group_name and keywords_input:
                keywords = [k.strip() for k in keywords_input.split(",") if k.strip()]
                if keywords:
                    keyword_groups.append({
                        "groupName": group_name,
                        "keywords": keywords
                    })
        
        if not keyword_groups:
            st.warning("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            st.stop()
        
        # ë‚ ì§œ ë²”ìœ„ ì„ íƒ
        st.sidebar.subheader("ğŸ“… ë‚ ì§œ ë²”ìœ„")
        today = date.today()
        start_date = st.sidebar.date_input(
            "ì‹œì‘ ë‚ ì§œ",
            value=today - timedelta(days=30),
            max_value=today
        )
        end_date = st.sidebar.date_input(
            "ì¢…ë£Œ ë‚ ì§œ",
            value=today,
            max_value=today
        )
        
        if start_date >= end_date:
            st.error("ì‹œì‘ ë‚ ì§œëŠ” ì¢…ë£Œ ë‚ ì§œë³´ë‹¤ ì´ì „ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
            st.stop()
        
        # ì§€ì—­ ì„¤ì •
        st.sidebar.subheader("ğŸŒ ì§€ì—­ ì„¤ì •")
        lat = st.sidebar.number_input(
            "ìœ„ë„",
            value=37.5665,
            min_value=-90.0,
            max_value=90.0,
            step=0.0001,
            format="%.4f"
        )
        lon = st.sidebar.number_input(
            "ê²½ë„",
            value=126.9780,
            min_value=-180.0,
            max_value=180.0,
            step=0.0001,
            format="%.4f"
        )
        
        # ë°ì´í„° ë¡œë”©
        with st.spinner("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
            daily_df, summary_df = load_data_with_keywords(
                keyword_groups, 
                start_date.strftime("%Y-%m-%d"), 
                end_date.strftime("%Y-%m-%d"),
                lat, lon
            )
        
        if daily_df is None or summary_df is None:
            st.error("ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í‚¤ì›Œë“œë‚˜ ë‚ ì§œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            st.stop()
    
    else:  # ê¸°ì¡´ CSV íŒŒì¼ ì‚¬ìš©
        daily_df, summary_df = load_data()
        
        if daily_df is None or summary_df is None:
            st.stop()
        
        # í‚¤ì›Œë“œ ê·¸ë£¹ ì„ íƒ
        selected_groups = st.sidebar.multiselect(
            "í‚¤ì›Œë“œ ê·¸ë£¹ ì„ íƒ",
            options=daily_df['group'].unique(),
            default=daily_df['group'].unique()
        )
        
        # ë‚ ì§œ ë²”ìœ„ ì„ íƒ
        date_range = st.sidebar.date_input(
            "ë‚ ì§œ ë²”ìœ„ ì„ íƒ",
            value=(daily_df['date'].min().date(), daily_df['date'].max().date()),
            min_value=daily_df['date'].min().date(),
            max_value=daily_df['date'].max().date()
        )
        
        # ë°ì´í„° í•„í„°ë§
        if selected_groups:
            filtered_daily = daily_df[daily_df['group'].isin(selected_groups)]
        else:
            filtered_daily = daily_df
        
        if len(date_range) == 2:
            start_date, end_date = date_range
            filtered_daily = filtered_daily[
                (filtered_daily['date'].dt.date >= start_date) & 
                (filtered_daily['date'].dt.date <= end_date)
            ]
        else:
            filtered_daily = daily_df
    
    # ë©”ì¸ ëŒ€ì‹œë³´ë“œ
    st.markdown("## ğŸ“ˆ ì£¼ìš” ì§€í‘œ")
    create_weather_metrics(summary_df)
    
    st.markdown("## ğŸ“Š ì‹œê³„ì—´ íŠ¸ë Œë“œ")
    create_trend_chart(daily_df)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("## ğŸŒ¤ï¸ ë‚ ì”¨ë³„ ë¹„êµ")
        create_weather_comparison_chart(summary_df)
    
    with col2:
        st.markdown("## ğŸ“Š ë‚ ì”¨ ë¶„í¬")
        create_weather_distribution_chart(daily_df)
    
    st.markdown("## ğŸ”— ìƒê´€ê´€ê³„ ë¶„ì„")
    create_correlation_heatmap(daily_df)
    
    # ë°ì´í„° í…Œì´ë¸”
    st.markdown("## ğŸ“‹ ìƒì„¸ ë°ì´í„°")
    
    # ìš”ì•½ í†µê³„
    st.subheader("ìš”ì•½ í†µê³„")
    st.dataframe(summary_df, use_container_width=True)
    
    # ì¼ë³„ ë°ì´í„° (ìƒ˜í”Œ)
    st.subheader("ì¼ë³„ ë°ì´í„° (ìµœê·¼ 10ì¼)")
    recent_data = daily_df.nlargest(10, 'date')[['date', 'group', 'ratio', 'day_type', 'precipitation_sum', 'rain_sum', 'snowfall_sum']]
    st.dataframe(recent_data, use_container_width=True)
    
    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
    st.markdown("## ğŸ’¾ ë°ì´í„° ë‹¤ìš´ë¡œë“œ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        csv_daily = daily_df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="ì¼ë³„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
            data=csv_daily,
            file_name=f"golf_weather_daily_{datetime.now().strftime('%Y%m%d')}.csv",
            mime="text/csv"
        )
    
    with col2:
        csv_summary = summary_df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="ìš”ì•½ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
            data=csv_summary,
            file_name=f"golf_weather_summary_{datetime.now().strftime('%Y%m%d')}.csv",
            mime="text/csv"
        )
    
    # ë°ì´í„° ì •ë³´ í‘œì‹œ
    st.markdown("---")
    st.markdown("### ğŸ“Š ë°ì´í„° ì •ë³´")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ì´ ë°ì´í„° ìˆ˜", f"{len(daily_df):,}ê°œ")
    
    with col2:
        st.metric("í‚¤ì›Œë“œ ê·¸ë£¹ ìˆ˜", f"{len(daily_df['group'].unique())}ê°œ")
    
    with col3:
        if not daily_df.empty:
            date_range = f"{daily_df['date'].min().strftime('%Y-%m-%d')} ~ {daily_df['date'].max().strftime('%Y-%m-%d')}"
            st.metric("ë¶„ì„ ê¸°ê°„", date_range)

if __name__ == "__main__":
    main()
